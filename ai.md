/ai&nbsp;&nbsp;&nbsp;&nbsp;[what is this?](https://slashpages.net/#ai)&nbsp;&nbsp;&nbsp;&nbsp;[other slash pages](/slashes.md)

I'm ethically opposed to almost all forms of AI, especially generative AI which has been trained on the works of millions of uncredited creators who did not consent to have their work used as training data. I have never included the output of any AI directly in any of my works and refuse to integrate it into any of my projects in a way where it's output will be viewed or executed by a user.except potentially as an assistive technology.

I will keep my mind open in case there is a day when we can have locally-hosted AI models, trained entirely with ethically sourced data, with the goal of enhancing - instead of replacing - human work. But until then, I will not use any AI tools and will not accept AI contributions to any of my projects.<br>

Problems that I have with AI:

  1. **Theft of intellectual property** - All major LLMs have been trained off of data with mixed levels of copyright and licenses, including strict policies. I am a big proponent of Open Source software along the lines of the [GPL](https://gnu.org/licenses/gpl-3.0.html). A primary characteristic of this license is that it is viral; modified versions of the code must be made available under the same license. If LLM are trained on GPL code, then anything written via the LLM should therefore be licensed with the GPL. I would be happy with that outcome, but at the same time I would also expect copyright holders of works under a closed license to enforce their copyright on any output from a model trained on their work. Although legislation is unlikely to make a decision against this abuse in either direction, I will still avoid using it out of caution and respect.
  2. **Unscrupulous collection of intellectual property** - Similar to the last point, but without regard for legal distinctions, it simply unethical to have taken the work of millions of people without their knowledge or consent. In the same way that a comedian stealing another comedian's joke does not illegally deprive the victim of their work, the victim is this entitled to being upset by it. Multiply this by millions of events and it should be clear that LLMs are simply hack comics across all sectors of human endeavor.
  3. **AI scraper abuse** - The scrapers that are used to train AI models are unscrupulous about how they collect their data. Many websites are having to take on exceptional measures to block traffic which can DDOS their systems. In this arms race, the least equipped admins are going to be the ones who cannot keep up, which is sure to drive some independent outlets off the open web and lead to an internet even more dominated by corporate giants, or more value extraction by CDNs and traffic filtering companies.
  4. **It makes bad "art"** - Whether that be prose, code, images or video, when a knowledgable viewer looks at the output of AI models, there is an uncanniness and lack of originality which can generally be sniffed out. I don't think the average person wants their creative experiences to be the result of a predictive algorithm which is incapable of creative thought, regardless of quality of the final product.
  5. **They want to take your job (but can't)** - The biggest potential value proposition of LLMs is to be able to satisfactorally replace the work of a large proportion of workers. However, with my limited experience testing these tools, it has become clear that the best trained models still make errors and hallucinate false information so confidently that a worker of equivalent skill needs to spend just as much time reviewing and fixing the work of the LLM as they would if they simply kept their job. Even if they could replace a large portion of workers, I don't think that this is a healthy thing to hope for in a capitalist economy. Any companies attempting to do so now are very likely to pay the price in terms of inferior products, vulnerabilities and consumer backlash.
  6. **Ludacris economics** - Up to 80% of US stock market growth this year can be attributed to the technology sector, almost entirely due to AI hype. At the same time, AI companies haven't really found their business model. It is contributing to an economic bubble larger that the dot-com bubble and perhaps larger than the sub-prime mortgage crisis. In the meantime, these companies are sucking up all of the investment which could be going to companies which are actually producing useful goods and services.
  7. **Energy use** - As of recent estimates expect that AI data centers could consume up to 10% of global electrity demand by the end of the decade. A small portion of this will use green and renewable energy. Of those that do, I would suggest that that energy could just be added to the grid instead, allowing for existing dirty sources of energy generation to be taken offline. I can only hope that the bubble bursts after this generation comes online and that local utilities can snap up the new resources at fire sale prices.
